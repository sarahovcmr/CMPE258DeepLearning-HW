{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pam_gray(b):\n",
    "    if len(b)>1:\n",
    "        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n",
    "    return 1-2*b[0]\n",
    "\n",
    "def qam(num_bits_per_symbol, normalize=True):\n",
    "    try:\n",
    "        assert num_bits_per_symbol % 2 == 0 # is even\n",
    "        assert num_bits_per_symbol >0 # is larger than zero\n",
    "    except AssertionError as error:\n",
    "        raise ValueError(\"num_bits_per_symbol must be a multiple of 2\") \\\n",
    "        from error\n",
    "    assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "\n",
    "    # Build constellation by iterating through all points\n",
    "    c = np.zeros([2**num_bits_per_symbol], dtype=np.complex64)\n",
    "    for i in range(0, 2**num_bits_per_symbol):\n",
    "        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                     dtype=np.int16)\n",
    "        c[i] = pam_gray(b[0::2]) + 1j*pam_gray(b[1::2]) # PAM in each dimension\n",
    "\n",
    "    if normalize: # Normalize to unit energy\n",
    "        n = int(num_bits_per_symbol/2)\n",
    "        qam_var = 1/(2**(n-2))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n",
    "        c /= np.sqrt(qam_var)\n",
    "    return c\n",
    "\n",
    "def CreateConstellation(constellation_type, num_bits_per_symbol,normalize=True):\n",
    "    num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "    if constellation_type==\"qam\":\n",
    "        assert num_bits_per_symbol%2 == 0 and num_bits_per_symbol>0,\\\n",
    "            \"num_bits_per_symbol must be a multiple of 2\"\n",
    "        num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "        print(\"Creating QAM constellation with {} bits per symbol\".format(num_bits_per_symbol))\n",
    "        points = qam(num_bits_per_symbol, normalize=normalize)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show(points, num_bits_per_symbol, labels=True, figsize=(7,7)):\n",
    "    \"\"\"Generate a scatter-plot of the constellation.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    labels : bool\n",
    "        If `True`, the bit labels will be drawn next to each constellation\n",
    "        point. Defaults to `True`.\n",
    "\n",
    "    figsize : Two-element Tuple, float\n",
    "        Width and height in inches. Defaults to `(7,7)`.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    : matplotlib.figure.Figure\n",
    "        A handle to a matplot figure object.\n",
    "    \"\"\"\n",
    "    maxval = np.max(np.abs(points))*1.05\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.xlim(-maxval, maxval)\n",
    "    plt.ylim(-maxval, maxval)\n",
    "    plt.scatter(np.real(points), np.imag(points))\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.xlabel(\"Real Part\")\n",
    "    plt.ylabel(\"Imaginary Part\")\n",
    "    plt.grid(True, which=\"both\", axis=\"both\")\n",
    "    plt.title(\"Constellation Plot\")\n",
    "    if labels is True:\n",
    "        for j, p in enumerate(points):\n",
    "            plt.annotate(\n",
    "                np.binary_repr(j, num_bits_per_symbol),\n",
    "                (np.real(p), np.imag(p))\n",
    "            )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating QAM constellation with 4 bits per symbol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS_PER_SYMBOL = 4 # QPSK: 2, QAM16\n",
    "points = CreateConstellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(points, NUM_BITS_PER_SYMBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def BinarySource(shape):\n",
    "    return np.random.randint(2, size=shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def complex_normal(shape, var=1.0):\n",
    "    stddev = np.sqrt(var/2)\n",
    "    xr = np.random.normal(loc=0.0, scale=stddev, size=shape)\n",
    "    xi = np.random.normal(loc=0.0, scale=stddev, size=shape)\n",
    "    x = xr + 1j*xi\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 return_indices=False,\n",
    "                 #dtype=tf.complex64,\n",
    "                 #**kwargs\n",
    "                ):\n",
    "          self.num_bits_per_symbol = num_bits_per_symbol\n",
    "          self.binary_base = 2**np.arange(num_bits_per_symbol-1, -1, -1, dtype=int) #array([2, 1], dtype=int32)\n",
    "          self.points = CreateConstellation(constellation_type, num_bits_per_symbol) #(4,)\n",
    "    \n",
    "    def create_symbol(self, inputs):\n",
    "        #inputs: (64, 1024) #batch_size, bits len\n",
    "        new_shape = [-1] + [int(inputs.shape[-1] / self.num_bits_per_symbol), self.num_bits_per_symbol] #[-1, 512, 2]\n",
    "        reinputs_reshaped = np.reshape(inputs, new_shape) #(64, 512, 2)\n",
    "        # Convert the last dimension to an integer\n",
    "        int_rep = reinputs_reshaped * self.binary_base #(64, 512, 2)\n",
    "        int_rep = np.sum(int_rep, axis=-1) #(64, 512)\n",
    "        int_rep = int_rep.astype(np.int32)\n",
    "        #print(int_rep.shape)\n",
    "        # Map integers to constellation symbols\n",
    "        #x = tf.gather(self.points, int_rep, axis=0)\n",
    "        symbs_list = [self.points[val_int] for val_int in int_rep]\n",
    "        symbols=np.array(symbs_list) #(64, 512) complex64\n",
    "        #print(symbols.dtype)\n",
    "        return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ebnodb2no(ebno_db, num_bits_per_symbol, coderate):\n",
    "    r\"\"\"Compute the noise variance `No` for a given `Eb/No` in dB.\n",
    "    Input\n",
    "    -----\n",
    "    ebno_db : float\n",
    "        The `Eb/No` value in dB.\n",
    "\n",
    "    num_bits_per_symbol : int\n",
    "        The number of bits per symbol.\n",
    "\n",
    "    coderate : float\n",
    "        The coderate used.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    : float\n",
    "        The value of :math:`N_o` in linear scale.\n",
    "    \"\"\"\n",
    "    #ebno = tf.math.pow(tf.cast(10., dtype), ebno_db/10.)\n",
    "    ebno = np.power(10, ebno_db/10.0)\n",
    "    energy_per_symbol = 1\n",
    "    tmp= (ebno * coderate * float(num_bits_per_symbol)) / float(energy_per_symbol)\n",
    "    n0 = 1/tmp\n",
    "    return n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class ComplexDataset(Dataset):\n",
    "    def __init__(self, num_bits_per_symbol, Frame_SIZE=64, Blocklength = 1024, DB_MIN=-10, DB_MAX=20, totaldbs=2000, constellation_type=\"qam\", data_type=np.complex64):\n",
    "        self.points = CreateConstellation(constellation_type, num_bits_per_symbol)\n",
    "        print(self.points.shape) #(4,) complex64\n",
    "        self.shape = ([Frame_SIZE, Blocklength])# Blocklength [64, 1024]\n",
    "        self.constellation_type = constellation_type\n",
    "        self.num_bits_per_symbol = num_bits_per_symbol\n",
    "        self.data_type = data_type\n",
    "        self.mapper=Mapper(constellation_type=constellation_type, num_bits_per_symbol=num_bits_per_symbol)\n",
    "\n",
    "        ebno_dbs=np.linspace(DB_MIN, DB_MAX, totaldbs)\n",
    "        np.random.shuffle(ebno_dbs)\n",
    "        self.ebno_dbs = ebno_dbs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ebno_db = self.ebno_dbs[index]\n",
    "\n",
    "        bits = BinarySource(self.shape)\n",
    "        #print(\"Shape of bits: \", bits.shape) #(64, 1024)\n",
    "\n",
    "        x=self.mapper.create_symbol(bits) #(64, 512) complex64\n",
    "\n",
    "        n0=ebnodb2no(ebno_db=ebno_db, num_bits_per_symbol=self.num_bits_per_symbol, coderate=1.0) #scalar 0.05\n",
    "        noise=complex_normal(x.shape, 1.0) #(64, 512) complex128\n",
    "        #print(noise.dtype)\n",
    "        noise = noise.astype(self.data_type)\n",
    "        noise *= np.sqrt(n0) \n",
    "        y=x+noise #(64, 512)\n",
    "        signal_complex = torch.from_numpy(y)\n",
    "\n",
    "        batch={}\n",
    "        batch['samples']=signal_complex #(64, 512)\n",
    "        batch['labels']=bits #(64, 1024)\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ebno_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating QAM constellation with 4 bits per symbol\n",
      "(16,)\n",
      "Creating QAM constellation with 4 bits per symbol\n"
     ]
    }
   ],
   "source": [
    "NUM_BITS_PER_SYMBOL = 4\n",
    "BATCH_SIZE = 32\n",
    "Frame_SIZE = 64\n",
    "Blocklength = 1024\n",
    "DB_MIN = -20\n",
    "DB_MAX = 20\n",
    "dataset = ComplexDataset(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, Frame_SIZE=Frame_SIZE, Blocklength=Blocklength, DB_MIN=DB_MIN, DB_MAX=DB_MAX, totaldbs=BATCH_SIZE*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "onesample = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['samples', 'labels'])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesample['samples'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1024)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesample['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train, validation and test split\n",
    "train_size = int(0.8 * len(dataset)) \n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set= torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "onebatch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 256])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['samples'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "onebatch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['samples'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpuid=0\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:'+str(gpuid))  # CUDA GPU 0\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel, self).__init__()\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=2, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        y = inputs #[32,64,256]\n",
    "        print(y.shape)\n",
    "   \n",
    "        # Stack the tensors along a new dimension (axis 0)\n",
    "        z = torch.stack([y.real, y.imag], dim=0) #[2, 32, 64, 256]\n",
    "        print(z.shape)\n",
    "        z = z.permute(1, 2, 3, 0) #[32, 64, 256, 2]\n",
    "        print(\"before linear1: \", z.shape)  # Print the shape after the convolutional layer\n",
    "\n",
    "        z = self.linear1(z) #[32,64,256,32]\n",
    "        print(\"After cnn1: \", z.shape)  # Print the shape after the convolutional layer\n",
    "\n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        print(\"After activation: \", z.shape)\n",
    "        z = self.linear2(z) #[32,64,256,4]\n",
    "        print(\"After linear2: \", z.shape)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "        print(\"After sigmoid: \", z.shape)\n",
    "        z = z.flatten(-2, -1) #[32, 64, 1024]\n",
    "        print(\"After flatten: \", z.shape)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Simplemodel(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 256])\n",
      "torch.Size([2, 32, 64, 256])\n",
      "before linear1:  torch.Size([32, 64, 256, 2])\n",
      "After cnn1:  torch.Size([32, 64, 256, 32])\n",
      "After activation:  torch.Size([32, 64, 256, 32])\n",
      "After linear2:  torch.Size([32, 64, 256, 4])\n",
      "After sigmoid:  torch.Size([32, 64, 256, 4])\n",
      "After flatten:  torch.Size([32, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "output = model(onebatch['samples']) #[32, 64, 512] =>[32, 64, 1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1 + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel1(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel1, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=4, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        # print(\"After cnn1: \", z.shape)  # Print the shape after the convolutional layer\n",
    "        z = self.activation(z)\n",
    "        # print(\"Before reshaping: \", z.shape)# [32, 2, 64, 256]\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        # print(\"After linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        # print(\"After linear2: \", z.shape)  # Print the shape before the linear layer\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "        # z = z.view(-1,32,4) #[batch_size, num_bits_per_symbol]\n",
    "        # print(\"After model: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Simplemodel1(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model1(onebatch['samples']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256, 4])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup loss and optimizer pip install ipywidgets\n",
    "loss_fn = nn.BCELoss() #nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test=torch.tensor([0,0,0,1,1,1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 1024])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['labels'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32, 64, 1024])) that is different to the input size (torch.Size([32, 64, 256, 4])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43monebatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\functional.py:3118\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3116\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3121\u001b[0m     )\n\u001b[0;32m   3123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([32, 64, 1024])) that is different to the input size (torch.Size([32, 64, 256, 4])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model2 + batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel2, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=4, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol) \n",
    "        self.batch_norm2d = nn.BatchNorm2d(num_features=4)\n",
    "\n",
    "       \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        # print(\"After cnn1: \", z.shape)  # Print the shape after the convolutional layer\n",
    "        z= self.batch_norm2d(z)\n",
    "        \n",
    "        z = self.activation(z)\n",
    "        # print(\"Before reshaping: \", z.shape)# [32, 2, 64, 256]\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        # print(\"After linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        # print(\"After linear2: \", z.shape)  # Print the shape before the linear layer\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "        # z = z.view(-1,32,4) #[batch_size, num_bits_per_symbol]\n",
    "        # print(\"After model: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Simplemodel2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = model2(onebatch['samples']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256, 4])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup loss and optimizer pip install ipywidgets\n",
    "loss_fn = nn.BCELoss() #nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test=torch.tensor([0,0,0,1,1,1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256, 4])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['labels'] = onebatch['labels'].view(32, 64, 256,4)\n",
    "onebatch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model2 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel2_2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8):\n",
    "        super(Simplemodel2_2, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.batch_norm2d = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z= self.batch_norm2d(z)\n",
    "\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_2 = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model2_2(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_channels: 4, loss: 0.7063580751419067\n",
      "out_channels: 8, loss: 0.6990205645561218\n",
      "out_channels: 16, loss: 0.6942257881164551\n",
      "out_channels: 32, loss: 0.6966648101806641\n",
      "out_channels: 64, loss: 0.6970628499984741\n",
      "out_channels: 128, loss: 0.6989198327064514\n",
      "out_channels: 256, loss: 0.6996558904647827\n"
     ]
    }
   ],
   "source": [
    "for out_channels in [4, 8, 16, 32, 64, 128, 256]:\n",
    "    model = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=out_channels)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"out_channels: {out_channels}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 4, loss: 0.6961226463317871\n",
      "scale 8, loss: 0.6955613493919373\n",
      "scale 16, loss: 0.6968110203742981\n",
      "scale 32, loss: 0.6984708309173584\n",
      "scale 64, loss: 0.6981329917907715\n",
      "scale 128, loss: 0.6973914504051208\n",
      "scale 256, loss: 0.6948480010032654\n"
     ]
    }
   ],
   "source": [
    "for scale in [4, 8, 16, 32, 64, 128, 256]:\n",
    "    model = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=64, scale=scale)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"scale {scale}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model 3 + more CNN layers, changed the out_channels and kernnel_size too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel3, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=8, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding = (5 - 1) // 2) # Add a CNN layer\n",
    "        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=256, kernel_size=9, stride=1, padding = (9 - 1) // 2) # Add a CNN layer\n",
    "\n",
    "        self.batch_norm2d1 = nn.BatchNorm2d(num_features=8)\n",
    "        self.batch_norm2d2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.batch_norm2d3 = nn.BatchNorm2d(num_features=256)\n",
    "\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=256, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z= self.batch_norm2d1(z)\n",
    "\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = self.cnn2(z) # [32, 2, 64, 256]\n",
    "        z= self.batch_norm2d2(z)\n",
    "\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        z = self.cnn3(z) # [32, 2, 64, 256]\n",
    "        z= self.batch_norm2d3(z)\n",
    "\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model3 = Simplemodel3(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = model3(onebatch['samples']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model 4 test different activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel4(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8, activation=nn.Sigmoid()):\n",
    "        super(Simplemodel4, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7068, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Simplemodel4(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model4(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Simplemodel4_1(nn.Module):\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8, activation=nn.Sigmoid()):\n",
    "        super(Simplemodel4_1, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = activation\n",
    "        self.softmax = nn.Softmax(dim=1)  # Specify the dimension, e.g., dim=1 for feature dimension\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        z = self.linear1(z)\n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        z = self.linear2(z)\n",
    "        z = self.softmax(z) #[32,64,256,32]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0874, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_1 = Simplemodel4_1(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model4_1(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: Sigmoid(), loss: 0.6996446847915649\n",
      "Activation: ReLU(), loss: 0.6946858167648315\n",
      "Activation: LeakyReLU(negative_slope=0.01), loss: 0.6936918497085571\n",
      "Activation: Tanh(), loss: 0.6972672343254089\n",
      "Activation: Softmax(dim=None), loss: 0.6952475309371948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for activation in [nn.Sigmoid(), nn.ReLU(), nn.LeakyReLU(), nn.Tanh(),nn.Softmax()]:\n",
    "    model = Simplemodel4(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=64, activation=activation)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"Activation: {activation}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model5 add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8):\n",
    "        super(Simplemodel5, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.cnn_dropout = nn.Dropout2d(p=0.2)  # Dropout for convolutional layers\n",
    "        self.linear_dropout = nn.Dropout(p=0.5)  # Dropout for fully connected layers\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "        z = self.cnn_dropout(z) # Dropout for convolutional layers\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        z = self.linear_dropout(z) # Dropout for fully connected layers\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = Simplemodel5(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model5(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainoutput folder: output\\exp0212\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainoutput=os.path.join('output','exp0212')\n",
    "os.makedirs(trainoutput, exist_ok=True)\n",
    "print(\"Trainoutput folder:\", trainoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_BERs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model=model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 12.73it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 369.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7048, Val Loss: 0.7029, Val BER: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 13.32it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 386.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.7048, Val Loss: 0.7021, Val BER: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.53it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 385.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.7048, Val Loss: 0.7032, Val BER: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 14.06it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 382.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.7048, Val Loss: 0.7238, Val BER: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.34it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 387.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7048, Val Loss: 0.7022, Val BER: 0.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.98it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 381.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.7048, Val Loss: 0.7032, Val BER: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.50it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 367.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.7048, Val Loss: 0.7046, Val BER: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.71it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 374.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.7048, Val Loss: 0.7094, Val BER: 0.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████▋                                 | 34/80 [00:03<00:04, 11.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[243], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# update the weights\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# accumulate the loss\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Print average loss for the epoch\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Training loop\n",
    "start_epoch = 0\n",
    "num_epochs =20\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for index, data_batch in enumerate(tqdm(train_loader)):\n",
    "        batch = {k: v.to(device) for k, v in data_batch.items()}\n",
    "        samples = batch['samples']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(samples)  # forward pass \n",
    "        labels = labels.view(32, 64, 256,4)\n",
    "        loss = loss_fn(outputs, labels) \n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # update the weights\n",
    "        total_loss += loss.item()  # accumulate the loss\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    BER_batch=[]\n",
    "    with torch.no_grad():\n",
    "        for index, data_batch in enumerate(tqdm(val_loader)):\n",
    "            batch = {k: v.to(device) for k, v in data_batch.items()}\n",
    "            samples = batch['samples']\n",
    "            labels = batch['labels']\n",
    "            labels = labels.view(1, 64, 256,4)\n",
    "\n",
    "            val_outputs = model(samples)\n",
    "            val_loss = loss_fn(val_outputs, labels)\n",
    "\n",
    "            # Convert probabilities to binary predictions (0 or 1)\n",
    "            binary_predictions = torch.round(val_outputs)\n",
    "\n",
    "            # Calculate Bit Error Rate (BER)\n",
    "            error_count = torch.sum(binary_predictions != labels).float()  # Count of unequal bits\n",
    "            error_rate = error_count / len(labels.flatten())  # Error rate calculation\n",
    "            BER_batch.append(error_rate.item())\n",
    "            \n",
    "    # Save performance details\n",
    "    train_losses.append(average_loss)\n",
    "    val_losses.append(val_loss.item())\n",
    "    BER_batch_mean=np.mean(BER_batch)\n",
    "    val_BERs.append(BER_batch_mean)#(BER.item())\n",
    "\n",
    "    # Print or log validation loss after each epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Val Loss: {val_loss:.4f}, Val BER: {BER_batch_mean:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel2, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=4, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        # print(\"After cnn1: \", z.shape)  # Print the shape after the convolutional layer\n",
    "        z = self.activation(z)\n",
    "        # print(\"Before reshaping: \", z.shape)# [32, 2, 64, 256]\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        # print(\"After linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        # print(\"Before linear1: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        # print(\"After linear2: \", z.shape)  # Print the shape before the linear layer\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "        # z = z.view(-1,32,4) #[batch_size, num_bits_per_symbol]\n",
    "        # print(\"After model: \", z.shape)  # Print the shape before the linear layer\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Simplemodel2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model2(onebatch['samples']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256, 4])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer pip install ipywidgets\n",
    "loss_fn = nn.BCELoss() #nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.tensor([0,0,0,1,1,1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256, 4])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebatch['labels'] = onebatch['labels'].view(32, 64, 256,4)\n",
    "onebatch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model2 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel2_2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8):\n",
    "        super(Simplemodel2_2, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_2 = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model2_2(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_channels: 4, loss: 0.6964638829231262\n",
      "out_channels: 8, loss: 0.6983799934387207\n",
      "out_channels: 16, loss: 0.7030550837516785\n",
      "out_channels: 32, loss: 0.696799635887146\n",
      "out_channels: 64, loss: 0.6935634016990662\n",
      "out_channels: 128, loss: 0.6966190934181213\n",
      "out_channels: 256, loss: 0.6962556838989258\n"
     ]
    }
   ],
   "source": [
    "for out_channels in [4, 8, 16, 32, 64, 128, 256]:\n",
    "    model = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=out_channels)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"out_channels: {out_channels}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 4, loss: 0.6937697529792786\n",
      "scale 8, loss: 0.6943815350532532\n",
      "scale 16, loss: 0.6958500742912292\n",
      "scale 32, loss: 0.69366455078125\n",
      "scale 64, loss: 0.6967389583587646\n",
      "scale 128, loss: 0.694881021976471\n",
      "scale 256, loss: 0.6944703459739685\n"
     ]
    }
   ],
   "source": [
    "for scale in [4, 8, 16, 32, 64, 128, 256]:\n",
    "    model = Simplemodel2_2(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=64, scale=scale)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"scale {scale}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256):\n",
    "        super(Simplemodel3, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=8, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "\n",
    "        scale = 8\n",
    "        self.linear1=nn.Linear(in_features=32, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = self.cnn2(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Simplemodel3(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model3(onebatch['samples']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel4(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8):\n",
    "        super(Simplemodel4, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        \n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        \n",
    "        z = self.linear1(z)\n",
    "        \n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "\n",
    "        z = self.linear2(z)\n",
    "        z = nn.Sigmoid()(z) #[32,64,256,32]\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Simplemodel4(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model4(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplemodel4(nn.Module):\n",
    "    def __init__(self, num_bits_per_symbol, H=64, W=256, out_channels=8, scale=8, activation=nn.Sigmoid()):\n",
    "        super(Simplemodel4, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=2, out_channels=out_channels, kernel_size=3, stride=1, padding = (3 - 1) // 2) # Add a CNN layer\n",
    "        self.linear1=nn.Linear(in_features=out_channels, out_features=scale*num_bits_per_symbol)\n",
    "        self.linear2=nn.Linear(in_features=scale*num_bits_per_symbol, out_features=num_bits_per_symbol)        \n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        z = torch.stack([y.real, y.imag], dim=1) #[2, 32, 64, 256]\n",
    "        z = self.cnn1(z) # [32, 2, 64, 256]\n",
    "        z = self.activation(z)\n",
    "        z = z.permute(0, 2, 3, 1) #[32, 64, 256, 2]\n",
    "        z = self.linear1(z)\n",
    "        z = self.activation(z)#[32,64,256,32]\n",
    "        z = self.linear2(z)\n",
    "        z = torch.sigmoid(z)#[32,64,256,32]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sigmoid.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[385], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model4 \u001b[38;5;241m=\u001b[39m Simplemodel4(num_bits_per_symbol\u001b[38;5;241m=\u001b[39mNUM_BITS_PER_SYMBOL, H\u001b[38;5;241m=\u001b[39mFrame_SIZE, W\u001b[38;5;241m=\u001b[39mBlocklength)\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel4\u001b[49m\u001b[43m(\u001b[49m\u001b[43monebatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m loss_fn(output,onebatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[384], line 18\u001b[0m, in \u001b[0;36mSimplemodel4.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(z)\u001b[38;5;66;03m#[32,64,256,32]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(z)\n\u001b[1;32m---> 18\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#[32,64,256,32]\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\anaconda3\\envs\\gpuenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:461\u001b[0m, in \u001b[0;36mModule.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Sigmoid.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model4 = Simplemodel4(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength)\n",
    "output = model4(onebatch['samples']) \n",
    "loss_fn(output,onebatch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation in [nn.Sigmoid(), nn.ReLU(), nn.LeakyReLU()]:\n",
    "    model = Simplemodel4(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, H=Frame_SIZE, W=Blocklength, out_channels=64, activation=activation)\n",
    "    output = model(onebatch['samples']) \n",
    "    loss = loss_fn(output,onebatch['labels'])\n",
    "    print(f\"Activation: {activation}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainoutput folder: output\\exp0212\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainoutput=os.path.join('output','exp0212')\n",
    "os.makedirs(trainoutput, exist_ok=True)\n",
    "print(\"Trainoutput folder:\", trainoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_BERs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model=model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.47it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 384.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7024, Val Loss: 0.7019, Val BER: 0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 13.16it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 383.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.7024, Val Loss: 0.7040, Val BER: 0.4980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.74it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 387.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.7024, Val Loss: 0.7018, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.36it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 388.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.7024, Val Loss: 0.7017, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.67it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 385.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7024, Val Loss: 0.7023, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 13.17it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 386.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.7024, Val Loss: 0.7019, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.51it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 389.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.7024, Val Loss: 0.7017, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.59it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 386.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.7024, Val Loss: 0.7016, Val BER: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 14.10it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 384.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.7024, Val Loss: 0.7023, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 12.75it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 390.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.7024, Val Loss: 0.7020, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.59it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 387.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.7024, Val Loss: 0.7012, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.67it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 388.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.7024, Val Loss: 0.7019, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 13.33it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 389.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.7024, Val Loss: 0.7027, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.64it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 383.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.7024, Val Loss: 0.7031, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 12.88it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 375.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.7024, Val Loss: 0.7015, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.60it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 387.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.7024, Val Loss: 0.7022, Val BER: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 13.07it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 388.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.7024, Val Loss: 0.7020, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.53it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 385.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.7024, Val Loss: 0.7021, Val BER: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.60it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 372.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.7024, Val Loss: 0.7033, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 12.97it/s]\n",
      "100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 366.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.7024, Val Loss: 0.7027, Val BER: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Training loop\n",
    "start_epoch = 0\n",
    "num_epochs =20\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for index, data_batch in enumerate(tqdm(train_loader)):\n",
    "        batch = {k: v.to(device) for k, v in data_batch.items()}\n",
    "        samples = batch['samples']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(samples)  # forward pass \n",
    "        labels = labels.view(32, 64, 256,4)\n",
    "        loss = loss_fn(outputs, labels) \n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # update the weights\n",
    "        total_loss += loss.item()  # accumulate the loss\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    BER_batch=[]\n",
    "    with torch.no_grad():\n",
    "        for index, data_batch in enumerate(tqdm(val_loader)):\n",
    "            batch = {k: v.to(device) for k, v in data_batch.items()}\n",
    "            samples = batch['samples']\n",
    "            labels = batch['labels']\n",
    "            labels = labels.view(1, 64, 256,4)\n",
    "\n",
    "            val_outputs = model(samples)\n",
    "            val_loss = loss_fn(val_outputs, labels)\n",
    "\n",
    "            # Convert probabilities to binary predictions (0 or 1)\n",
    "            binary_predictions = torch.round(val_outputs)\n",
    "\n",
    "            # Calculate Bit Error Rate (BER)\n",
    "            error_count = torch.sum(binary_predictions != labels).float()  # Count of unequal bits\n",
    "            error_rate = error_count / len(labels.flatten())  # Error rate calculation\n",
    "            BER_batch.append(error_rate.item())\n",
    "            \n",
    "    # Save performance details\n",
    "    train_losses.append(average_loss)\n",
    "    val_losses.append(val_loss.item())\n",
    "    BER_batch_mean=np.mean(BER_batch)\n",
    "    val_BERs.append(BER_batch_mean)#(BER.item())\n",
    "\n",
    "    # Print or log validation loss after each epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Val Loss: {val_loss:.4f}, Val BER: {BER_batch_mean:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the final trained model\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}\n",
    "modelsave_path = os.path.join(trainoutput, 'simple_model.pth')\n",
    "torch.save(checkpoint, modelsave_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Training Loss and Validation Loss\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Validation BER\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(val_BERs, label='Validation BER')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BER')\n",
    "plt.legend()\n",
    "plt.title('Bit Error Rate (BER) on validation set')\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
